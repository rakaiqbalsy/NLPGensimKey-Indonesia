{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BISMILLAH \n",
    "\n",
    "# Import Library\n",
    "\n",
    "#NLTK & Newspaper\n",
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.cluster.util import cosine_distance\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from newspaper import Article\n",
    "\n",
    "import re\n",
    "from pprint import pprint\n",
    "import string \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
    "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
    "\n",
    "from gensim.summarization.summarizer import summarize as summary\n",
    "from gensim.summarization import keywords as key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping dengan article nltk\n",
    "def scrap_data(url: str) -> tuple:\n",
    "    str_text = Article(url)\n",
    "    str_text.download()\n",
    "    str_text.parse()\n",
    "    data = str_text.text\n",
    "   \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "#Stagging\n",
    "def stagging_text(text):\n",
    "    text_str = sent_tokenize(text)\n",
    "    pecahan = [word_tokenize(sent) for sent in text_str]\n",
    "    return pecahan\n",
    "\n",
    "# Stemming\n",
    "def steman(text):   \n",
    "    factory = StemmerFactory()\n",
    "    stemmer = factory.create_stemmer()\n",
    "    kata = stemmer.stem(text)\n",
    "    \n",
    "#     katadasar = {}\n",
    "#     kal = str(text)\n",
    "#     for kata in kal:\n",
    "#         katadasar = stemmer.stem(kata)\n",
    "    \n",
    "    return kata\n",
    "    \n",
    "#     stemer = {}\n",
    "#     kal = str(text)\n",
    "    \n",
    "#     for stem in range(len(kal)):\n",
    "#         factory = StemmerFactory()\n",
    "#         stemmer = factory.create_stemmer()\n",
    "#         stemer[stem] = stemmer.stem(kal[stem])\n",
    "    \n",
    "#     return stemer\n",
    "\n",
    "\n",
    "#lowercase\n",
    "def text_lowercase(text): \n",
    "    return text.lower()\n",
    "\n",
    "# Remove numbers \n",
    "def remove_numbers(text): \n",
    "    result = re.sub(r'\\d+', '', text) \n",
    "    return result \n",
    "\n",
    "# remove punctuation \n",
    "# def remove_punctuation(text): \n",
    "#     translator = str.maketrans('', '', string.punctuation) \n",
    "#     return text.translate(translator)\n",
    "\n",
    "# remove whitespace from text \n",
    "def remove_whitespace(text): \n",
    "    return  \" \".join(text.split()) \n",
    "\n",
    "# remove stopwords function \n",
    "def remove_stopwords(text):\n",
    "    \n",
    "    stopword_file = open(\"stopword.txt\", \"r\") #ambil data stopword\n",
    "    \n",
    "    lots_of_stopwords = []\n",
    "    for line in stopword_file.readlines():\n",
    "        lots_of_stopwords.append(str(line.strip()))\n",
    "    \n",
    "    stop_words = set(lots_of_stopwords) \n",
    "    word_tokens = word_tokenize(text) \n",
    "    filtered_text = [word for word in word_tokens if word not in stop_words] \n",
    "    return filtered_text\n",
    "\n",
    "def stopword_plus(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    listStopword =  set(stopwords.words('indonesian'))\n",
    "    \n",
    "    removed = []\n",
    "    for t in tokens:\n",
    "        if t not in listStopword:\n",
    "            removed.append(t)\n",
    "    \n",
    "    return removed\n",
    "    \n",
    "#     From NLTK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarizeTextrank(text, ratio=0.5): \n",
    "    return summary(text, ratio)\n",
    "\n",
    "def keywordTextrank(text, lemmatize=False):\n",
    "    return key(text, words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://mui.or.id/tanya-jawab-keislaman/28384/apakah-menggunakan-cadar-itu-hukumnya-wajib/'\n",
    "url = 'https://muslim.or.id/53382-jika-suci-dari-haid-di-waktu-ashar-apakah-juga-harus-shalat-dzuhur.html'\n",
    "sentence = scrap_data(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Implementation\n",
    "\n",
    "lower = text_lowercase(sentence)\n",
    "rnumber = remove_numbers(lower)\n",
    "#punctuation = remove_punctuation(rnumber)\n",
    "white_space = remove_whitespace(rnumber)\n",
    "stopword_list = remove_stopwords(white_space)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sentence = ' '.join(stopword_list)\n",
    "stop_plus = stopword_plus(new_sentence)\n",
    "\n",
    "kalimat = ' '.join(stop_plus)\n",
    "stemer = steman(kalimat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "textrankSentence = summarizeTextrank(kalimat)\n",
    "textrankKeyword = keywordTextrank(kalimat).split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatwa syaikh muhammad bin shalih al- ‘ utsaimin rahimahullah wanita suci haidh nifas ashar wajib shalat dzuhur shalat ashar ; wajib shalat kecuali shalat ashar ?\n",
      "pendapat terkuat wanita memiliki kewajiban shalat kecuali shalat ashar .\n",
      "dalil wajibnya shalat dzuhur ( wanita ) .\n",
      "nabi shallallahu ‘ alaihi wa sallam bersabda وَمَنْ أَدْرَكَ رَكْعَةً مِنَ العَصْرِ قَبْلَ أَنْ تَغْرُبَ الشَّمْسُ، فَقَدْ أَدْرَكَ العَصْرَ “ mendapati raka ’ at shalat ashar matahari tenggelam shalat ashar .\n",
      ") hadits nabi shallallahu ‘ alaihi wa sallam mendapati shalat dzuhur .\n",
      "seandainya shalat dzuhur diwajibkan kondisi nabi shallallahu ‘ alaihi wa sallam .\n",
      "wanita haidh masuk shalat dzuhur ( shalat dzuhur pen .\n",
      ") kewajiban qadha ’ untuknya ( suci haidh pen .\n",
      ") kecuali qadha ’ shalat dzuhur qadha ’ shalat ashar .\n",
      "pendapat kuat kewajiban wanita kecuali shalat ashar dalil nash ( hadits ) dalil qiyas .\n",
      "kondisinya wanita suci haidh habisnya shalat isya ’ .\n",
      "kewajiban wanita kecuali shalat isya ’ .\n"
     ]
    }
   ],
   "source": [
    "print(textrankSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shalat', 'wanita', 'kewajiban', 'ashar', 'dalil']\n"
     ]
    }
   ],
   "source": [
    "print(textrankKeyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
